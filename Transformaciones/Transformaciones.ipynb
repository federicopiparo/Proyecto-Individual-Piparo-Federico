{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Transformaciones\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df = pd.read_csv('C:\\\\Users\\\\fede\\\\Desktop\\\\LABs 1\\\\Proyecto individual - Federico Piparo\\\\Transformaciones\\\\Movies\\\\movies_dataset.csv', low_memory=False)\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\fede\\\\Desktop\\\\LABs 1\\\\Proyecto individual - Federico Piparo\\\\Transformaciones\\\\Movies\\\\credits.csv', low_memory=False)\n",
    "\n",
    "#'''trabajaré al mismo tiempo con el DF Credits, ya que algunas funciones de la API necesitan datos provenientes de este'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los convertimos a 'parquet' para optimizar el rendimineto\n",
    "df.to_parquet('data_compressed.parquet', engine='pyarrow', compression='snappy')\n",
    "# Guardar con compresión snappy\n",
    "df2.to_parquet('data_compressed.parquet', engine='pyarrow', compression='snappy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas eliminadas: 17\n",
      "Número de filas duplicadas eliminadas en el segundo DF: 37\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de filas duplicadas\n",
    "duplicados = df.duplicated().sum()\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "df_sin_duplicados = df.drop_duplicates()\n",
    "\n",
    "# Almacenar el número de filas duplicadas en una variable, esto simplemente para verificar que si existían filas duplicadas\n",
    "numero_de_duplicados = duplicados\n",
    "\n",
    "print(\"Número de filas duplicadas eliminadas:\", numero_de_duplicados)\n",
    "\n",
    "#segundo DF\n",
    "# Contar el número de filas duplicadas \n",
    "duplicados = df2.duplicated().sum()\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "df_sin_duplicados = df2.drop_duplicates()\n",
    "\n",
    "# Almacenar el número de filas duplicadas en una variable, esto simplemente para verificar que si existían filas duplicadas\n",
    "numero_de_duplicados = duplicados\n",
    "print(\"Número de filas duplicadas eliminadas en el segundo DF:\", numero_de_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage.'''\n",
    "df = df.drop(columns=['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Los valores nulos del campo release date deben eliminarse.'''\n",
    "\n",
    "df = df.dropna(subset=['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0.'''\n",
    "\n",
    "df[['revenue', 'budget']] = df[['revenue', 'budget']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno.'''\n",
    "\n",
    "#convertimos las fechas al datatype datetime\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce') \n",
    "df['release_year'] = df['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget,\n",
    "cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.'''\n",
    "# Convertir las columnas 'revenue' y 'budget' a tipo numérico\n",
    "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "# Rellenar valores nulos en 'revenue' y 'budget' con 0\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "\n",
    "# Crear la columna 'return' calculando revenue / budget\n",
    "# Usar np.where para evitar división por 0\n",
    "import numpy as np\n",
    "df['return'] = np.where(df['budget'] == 0, 0, df['revenue'] / df['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:21: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  BTC_df = df['belongs_to_collection'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:27: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  genres_df = df['genres'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:28: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  production_companies_df = df['production_companies'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:29: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  production_countries_df = df['production_countries'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:30: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  spoken_languages_df = df['spoken_languages'].apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "''' Algunos campos, como belongs_to_collection, production_companies y otros (ver diccionario de datos) están anidados, esto es o bien tienen un diccionario o una\n",
    "lista como valores en cada fila, ¡deberán desanidarlos para poder y unirlos al dataset de nuevo hacer alguna de las consultas de la API!\n",
    "O bien buscar la manera de acceder a esos datos sin desanidarlos.'''\n",
    "# Función para convertir cadenas a diccionarios o listas\n",
    "def convertir_en_obj(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return x  # Retorna la cadena si no es un diccionario válido\n",
    "    return x\n",
    "\n",
    "# Aplicar la conversión a las series \n",
    "df['belongs_to_collection'] = df['belongs_to_collection'].apply(convertir_en_obj)\n",
    "df['genres'] = df['genres'].apply(convertir_en_obj)\n",
    "df['production_companies'] = df['production_companies'].apply(convertir_en_obj)\n",
    "df['production_countries'] = df['production_countries'].apply(convertir_en_obj)\n",
    "df['spoken_languages'] = df['spoken_languages'].apply(convertir_en_obj)\n",
    "\n",
    "# Desanidar diccionarios\n",
    "BTC_df = df['belongs_to_collection'].apply(pd.Series)\n",
    "BTC_df = BTC_df.drop(columns = 0, errors='ignore')  # Eliminar columna de índice si existe\n",
    "nuevos_nombres_BTC = ['BTCid', 'BTCname', 'BTCposter_path', 'BTCbackdrop_path']\n",
    "BTC_df.columns = nuevos_nombres_BTC\n",
    "\n",
    "# Desanidar listas\n",
    "genres_df = df['genres'].apply(pd.Series)\n",
    "production_companies_df = df['production_companies'].apply(pd.Series)\n",
    "production_countries_df = df['production_countries'].apply(pd.Series)\n",
    "spoken_languages_df = df['spoken_languages'].apply(pd.Series)\n",
    "\n",
    "# Asegurarse de que no haya nombres de columnas duplicados\n",
    "genres_df = genres_df.rename(columns=lambda x: f'genre_{x}')\n",
    "production_companies_df = production_companies_df.rename(columns=lambda x: f'company_{x}')\n",
    "production_countries_df = production_countries_df.rename(columns=lambda x: f'country_{x}')\n",
    "spoken_languages_df = spoken_languages_df.rename(columns=lambda x: f'language_{x}')\n",
    "\n",
    "# Eliminar las columnas originales\n",
    "df = df.drop(columns=['belongs_to_collection', 'genres', 'production_companies', 'production_countries', 'spoken_languages'])\n",
    "\n",
    "# Unir los DataFrames desanidado al DataFrame original\n",
    "df = df.join(BTC_df)\n",
    "df = df.join(production_companies_df)\n",
    "df = df.join(production_countries_df)\n",
    "df = df.join(spoken_languages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Transformaciones sobre credits (API)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Al ser un DF muy grande y necesitar solo partes muy especificas de los diccionarios que componen las series del DF,\n",
    "en vez de desanidarlo todo, utilizaremos otras tecnicas para extraer los datos que necesitamos, y con estos crearemos una nueva tabla,\n",
    "esta misma contendra solamente los datos que necesitamos para las funciones de nuestra API '''\n",
    "\n",
    "# Extraer los nombres de la columna 'cast'\n",
    "names = df2['cast'].apply(lambda x: [item['name'] for item in ast.literal_eval(x) if 'name' in item])\n",
    "\n",
    "# Convertir la serie 'names' en un DataFrame\n",
    "names_df = pd.DataFrame(names.tolist())\n",
    "\n",
    "# Añadir la palabra 'nombre' delante del nombre de cada serie\n",
    "names_df.columns = ['nombre_' + str(col) for col in names_df.columns]\n",
    "\n",
    "# Crear una serie que contenga únicamente el nombre del director\n",
    "names_df['Nombre_Director'] = df2['crew'].apply(\n",
    "    lambda x: next((item['name'] for item in ast.literal_eval(x) if item.get('job') == 'Director'), None)\n",
    ")\n",
    "\n",
    "# volvemos a añadir los ID a las filas, ya que los necesitaremos luego para hacer un \"Join\"\n",
    "names_df['id'] = df2['id'].astype(int)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_0</th>\n",
       "      <th>nombre_1</th>\n",
       "      <th>nombre_2</th>\n",
       "      <th>nombre_3</th>\n",
       "      <th>nombre_4</th>\n",
       "      <th>nombre_5</th>\n",
       "      <th>nombre_6</th>\n",
       "      <th>nombre_7</th>\n",
       "      <th>nombre_8</th>\n",
       "      <th>nombre_9</th>\n",
       "      <th>...</th>\n",
       "      <th>nombre_305</th>\n",
       "      <th>nombre_306</th>\n",
       "      <th>nombre_307</th>\n",
       "      <th>nombre_308</th>\n",
       "      <th>nombre_309</th>\n",
       "      <th>nombre_310</th>\n",
       "      <th>nombre_311</th>\n",
       "      <th>nombre_312</th>\n",
       "      <th>Nombre_Director</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Hanks</td>\n",
       "      <td>Tim Allen</td>\n",
       "      <td>Don Rickles</td>\n",
       "      <td>Jim Varney</td>\n",
       "      <td>Wallace Shawn</td>\n",
       "      <td>John Ratzenberger</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>John Morris</td>\n",
       "      <td>Erik von Detten</td>\n",
       "      <td>Laurie Metcalf</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nombre_0   nombre_1     nombre_2    nombre_3       nombre_4  \\\n",
       "0  Tom Hanks  Tim Allen  Don Rickles  Jim Varney  Wallace Shawn   \n",
       "\n",
       "            nombre_5     nombre_6     nombre_7         nombre_8  \\\n",
       "0  John Ratzenberger  Annie Potts  John Morris  Erik von Detten   \n",
       "\n",
       "         nombre_9  ... nombre_305 nombre_306 nombre_307 nombre_308 nombre_309  \\\n",
       "0  Laurie Metcalf  ...       None       None       None       None       None   \n",
       "\n",
       "  nombre_310 nombre_311 nombre_312 Nombre_Director   id  \n",
       "0       None       None       None   John Lasseter  862  \n",
       "\n",
       "[1 rows x 315 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#estas transformaciones las hago ya habiendo casi finalizado el trabajo, para el sistema de recomendación\n",
    "#He decidido que para este crearé un nuevo DF, el cual será una versión reducida del mismo, y que mantendrá unicamente las series que considere pertinentes\n",
    "\n",
    "---\n",
    "\n",
    "### Exportación de los Datafames\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('transformados.parquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
