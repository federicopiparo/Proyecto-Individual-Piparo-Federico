{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Transformaciones\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df = pd.read_csv('C:\\\\Users\\\\fede\\\\Desktop\\\\LABs 1\\\\Proyecto individual - Federico Piparo\\\\Transformaciones\\\\Movies\\\\movies_dataset.csv', low_memory=False)\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\fede\\\\Desktop\\\\LABs 1\\\\Proyecto individual - Federico Piparo\\\\Transformaciones\\\\Movies\\\\credits.csv', low_memory=False)\n",
    "\n",
    "#'''trabajaré al mismo tiempo con el DF Credits, ya que algunas funciones de la API necesitan datos provenientes de este'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los convertimos a 'parquet' para optimizar el rendimineto\n",
    "df.to_parquet('data_compressed.parquet', engine='pyarrow', compression='snappy')\n",
    "# Guardar con compresión snappy\n",
    "df2.to_parquet('data_compressed.parquet', engine='pyarrow', compression='snappy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas eliminadas: 17\n",
      "Número de filas duplicadas eliminadas en el segundo DF: 37\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de filas duplicadas\n",
    "duplicados = df.duplicated().sum()\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "df_sin_duplicados = df.drop_duplicates()\n",
    "\n",
    "# Almacenar el número de filas duplicadas en una variable, esto simplemente para verificar que si existían filas duplicadas\n",
    "numero_de_duplicados = duplicados\n",
    "\n",
    "print(\"Número de filas duplicadas eliminadas:\", numero_de_duplicados)\n",
    "\n",
    "#segundo DF\n",
    "# Contar el número de filas duplicadas \n",
    "duplicados = df2.duplicated().sum()\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "df_sin_duplicados = df2.drop_duplicates()\n",
    "\n",
    "# Almacenar el número de filas duplicadas en una variable, esto simplemente para verificar que si existían filas duplicadas\n",
    "numero_de_duplicados = duplicados\n",
    "print(\"Número de filas duplicadas eliminadas en el segundo DF:\", numero_de_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage.'''\n",
    "df = df.drop(columns=['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Los valores nulos del campo release date deben eliminarse.'''\n",
    "\n",
    "df = df.dropna(subset=['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0.'''\n",
    "\n",
    "df[['revenue', 'budget']] = df[['revenue', 'budget']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno.'''\n",
    "\n",
    "#convertimos las fechas al datatype datetime\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce') \n",
    "df['release_year'] = df['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget,\n",
    "cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.'''\n",
    "# Convertir las columnas 'revenue' y 'budget' a tipo numérico\n",
    "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "# Rellenar valores nulos en 'revenue' y 'budget' con 0\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "\n",
    "# Crear la columna 'return' calculando revenue / budget\n",
    "# Usar np.where para evitar división por 0\n",
    "import numpy as np\n",
    "df['return'] = np.where(df['budget'] == 0, 0, df['revenue'] / df['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:21: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  BTC_df = df['belongs_to_collection'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:27: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  genres_df = df['genres'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:28: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  production_companies_df = df['production_companies'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:29: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  production_countries_df = df['production_countries'].apply(pd.Series)\n",
      "C:\\Users\\fede\\AppData\\Local\\Temp\\ipykernel_12724\\1652706673.py:30: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  spoken_languages_df = df['spoken_languages'].apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "''' Algunos campos, como belongs_to_collection, production_companies y otros (ver diccionario de datos) están anidados, esto es o bien tienen un diccionario o una\n",
    "lista como valores en cada fila, ¡deberán desanidarlos para poder y unirlos al dataset de nuevo hacer alguna de las consultas de la API!\n",
    "O bien buscar la manera de acceder a esos datos sin desanidarlos.'''\n",
    "# Función para convertir cadenas a diccionarios o listas\n",
    "def convertir_en_obj(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return x  # Retorna la cadena si no es un diccionario válido\n",
    "    return x\n",
    "\n",
    "# Aplicar la conversión a las series \n",
    "df['belongs_to_collection'] = df['belongs_to_collection'].apply(convertir_en_obj)\n",
    "df['genres'] = df['genres'].apply(convertir_en_obj)\n",
    "df['production_companies'] = df['production_companies'].apply(convertir_en_obj)\n",
    "df['production_countries'] = df['production_countries'].apply(convertir_en_obj)\n",
    "df['spoken_languages'] = df['spoken_languages'].apply(convertir_en_obj)\n",
    "\n",
    "# Desanidar diccionarios\n",
    "BTC_df = df['belongs_to_collection'].apply(pd.Series)\n",
    "BTC_df = BTC_df.drop(columns = 0, errors='ignore')  # Eliminar columna de índice si existe\n",
    "nuevos_nombres_BTC = ['BTCid', 'BTCname', 'BTCposter_path', 'BTCbackdrop_path']\n",
    "BTC_df.columns = nuevos_nombres_BTC\n",
    "\n",
    "# Desanidar listas\n",
    "genres_df = df['genres'].apply(pd.Series)\n",
    "production_companies_df = df['production_companies'].apply(pd.Series)\n",
    "production_countries_df = df['production_countries'].apply(pd.Series)\n",
    "spoken_languages_df = df['spoken_languages'].apply(pd.Series)\n",
    "\n",
    "# Asegurarse de que no haya nombres de columnas duplicados\n",
    "genres_df = genres_df.rename(columns=lambda x: f'genre_{x}')\n",
    "production_companies_df = production_companies_df.rename(columns=lambda x: f'company_{x}')\n",
    "production_countries_df = production_countries_df.rename(columns=lambda x: f'country_{x}')\n",
    "spoken_languages_df = spoken_languages_df.rename(columns=lambda x: f'language_{x}')\n",
    "\n",
    "# Eliminar las columnas originales\n",
    "df = df.drop(columns=['belongs_to_collection', 'genres', 'production_companies', 'production_countries', 'spoken_languages'])\n",
    "\n",
    "# Unir los DataFrames desanidado al DataFrame original\n",
    "df = df.join(BTC_df)\n",
    "df = df.join(production_companies_df)\n",
    "df = df.join(production_countries_df)\n",
    "df = df.join(spoken_languages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Transformaciones sobre credits (API)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Al ser un DF muy grande y necesitar solo partes muy especificas de los diccionarios que componen las series del DF,\n",
    "en vez de desanidarlo todo, utilizaremos otras tecnicas para extraer los datos que necesitamos, y con estos crearemos una nueva tabla,\n",
    "esta misma contendra solamente los datos que necesitamos para las funciones de nuestra API '''\n",
    "\n",
    "# Extraer los nombres de la columna 'cast'\n",
    "names = df2['cast'].apply(lambda x: [item['name'] for item in ast.literal_eval(x) if 'name' in item])\n",
    "\n",
    "# Convertir la serie 'names' en un DataFrame\n",
    "names_df = pd.DataFrame(names.tolist())\n",
    "\n",
    "# Añadir la palabra 'nombre' delante del nombre de cada serie\n",
    "names_df.columns = ['nombre_' + str(col) for col in names_df.columns]\n",
    "\n",
    "# Crear una serie que contenga únicamente el nombre del director\n",
    "names_df['Nombre_Director'] = df2['crew'].apply(\n",
    "    lambda x: next((item['name'] for item in ast.literal_eval(x) if item.get('job') == 'Director'), None)\n",
    ")\n",
    "\n",
    "# volvemos a añadir los ID a las filas, ya que los necesitaremos luego para hacer un \"Join\"\n",
    "names_df['id'] = df2['id'].astype(int)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exportación de los Datafames\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('transformados.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#estas transformaciones las hago ya habiendo casi finalizado el trabajo, para el sistema de recomendación\n",
    "#He decidido que para este crearé un nuevo DF, el cual será una versión reducida del mismo, y que mantendrá unicamente las series que considere pertinentes\n",
    "\n",
    "---\n",
    "\n",
    "### Transformaciones para Machine learning\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "df = pd.read_parquet('C:\\\\Users\\\\fede\\\\Desktop\\\\LABs 1\\\\Proyecto individual - Federico Piparo\\\\Transformaciones\\\\transformados.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#por cuestiones de rendimiento deberemos reducir realmente mucho el numero de filas y series, no pudiendo usar series que contengan strings\n",
    "#tambien reduciremos muchisimo el numero de filas, para que el archivo final no supere el peso de 512 mb impuesto por render\n",
    "#vamos a crear nuestra matriz de similitud del coseno y luego importarla a nuestro \"main.py\"\n",
    "series_ML =['title','popularity', 'runtime', 'vote_average']\n",
    "df = df[series_ML]\n",
    "df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear una columna que cuenta el número de ceros y NaNs por fila\n",
    "df['count_zeros_nans'] = (df == 0).sum(axis=1) + df.isna().sum(axis=1)\n",
    "\n",
    "# Ordenar el DataFrame por esta nueva columna en orden descendente\n",
    "df = df.sort_values(by='count_zeros_nans', ascending=False)\n",
    "\n",
    "# Eliminar filas con más valores 0 o NaN\n",
    "df = df.iloc[len(df) // 2:]\n",
    "df = df.iloc[len(df) // 2:]\n",
    "df = df.iloc[len(df) // 2:]\n",
    "df = df.iloc[len(df) // 2:]\n",
    "df = df.iloc[len(df) // 2:]\n",
    "\n",
    "\n",
    "# Eliminar la columna auxiliar 'count_zeros_nans'\n",
    "df = df.drop(columns=['count_zeros_nans'])\n",
    "\n",
    "\n",
    "# Reemplazar 0 por NaN en todas las columnas excepto 'title'\n",
    "df.loc[:, df.columns != 'title'] = df.loc[:, df.columns != 'title'].replace(0, np.nan)\n",
    "\n",
    "# Imputar NaNs con el promedio de cada columna (excepto 'title')\n",
    "df.loc[:, df.columns != 'title'] = df.loc[:, df.columns != 'title'].fillna(df.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torch Song</td>\n",
       "      <td>0.574971</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of Human Hearts</td>\n",
       "      <td>0.404973</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Princess O'Rourke</td>\n",
       "      <td>0.319906</td>\n",
       "      <td>94.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Whisperers</td>\n",
       "      <td>0.470596</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shogun's Ninja</td>\n",
       "      <td>0.977162</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>Cyrus</td>\n",
       "      <td>10.420010</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>The Human Centipede (First Sequence)</td>\n",
       "      <td>12.845850</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>The Ten Commandments</td>\n",
       "      <td>1.725825</td>\n",
       "      <td>136.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>This Is the Army</td>\n",
       "      <td>0.800156</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Cry in the Woods</td>\n",
       "      <td>0.110872</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  popularity  runtime  vote_average\n",
       "0                               Torch Song    0.574971     90.0           5.4\n",
       "1                          Of Human Hearts    0.404973    103.0           2.3\n",
       "2                        Princess O'Rourke    0.319906     94.0           6.5\n",
       "3                           The Whisperers    0.470596    105.0           6.6\n",
       "4                           Shogun's Ninja    0.977162    117.0           5.3\n",
       "...                                    ...         ...      ...           ...\n",
       "1416                                 Cyrus   10.420010     91.0           6.1\n",
       "1417  The Human Centipede (First Sequence)   12.845850     92.0           4.9\n",
       "1418                  The Ten Commandments    1.725825    136.0           7.0\n",
       "1419                      This Is the Army    0.800156    121.0           8.3\n",
       "1420                      Cry in the Woods    0.110872     97.0           6.5\n",
       "\n",
       "[1421 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer características numéricas para las recomendaciones\n",
    "features = df[['popularity', 'runtime', 'vote_average']]\n",
    "\n",
    "# Normalizar las características\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Calcular similitudes usando el coseno\n",
    "cosine_sim = cosine_similarity(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('similitud_del_coseno.npy', cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
